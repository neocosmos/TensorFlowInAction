{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.name_scope 主要结合 tf.Variable() 来使用，方便参数命名管理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('conv1') as scope:\n",
    "    weights1 = tf.Variable([1.0, 2.0], name='weights')\n",
    "    bias1 = tf.Variable([0.3], name='bias')\n",
    "with tf.name_scope('conv2') as scope:\n",
    "    weights2 = tf.Variable([4.0, 2.0], name='weights')\n",
    "    bias2 = tf.Variable([0.33], name='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1/weights:0\n",
      "conv2/weights:0\n"
     ]
    }
   ],
   "source": [
    "print weights1.name\n",
    "print weights2.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1_1/weights:0\n"
     ]
    }
   ],
   "source": [
    "# 执行完 with 里边的语句之后，这个 conv1/ 和 conv2/ 空间还是在内存中的。这时候如果再次执行上面的代码\n",
    "# 就会再生成其他命名空间\n",
    "with tf.name_scope('conv1') as scope:\n",
    "    weights1 = tf.Variable([1.0, 2.0], name='weights')\n",
    "    bias1 = tf.Variable([0.3], name='bias')\n",
    "print weights1.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.variable_scope() 主要结合 tf.get_variable() 来使用，实现 变量共享。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v_scope/Weights:0\n",
      "v_scope/Weights:0\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('v_scope') as scope1:\n",
    "    Weights1 = tf.get_variable('Weights', shape=[2,3])\n",
    "    bias1 = tf.get_variable('bias', shape=[3])\n",
    "\n",
    "# 下面来共享上面已经定义好的变量\n",
    "# note: 在下面的 scope 中的变量必须已经定义过了，才能设置 reuse=True，否则会报错\n",
    "with tf.variable_scope('v_scope', reuse=True) as scope2:\n",
    "    Weights2 = tf.get_variable('Weights')\n",
    "\n",
    "print Weights1.name\n",
    "print Weights2.name\n",
    "# 可以看到这两个引用名称指向的是同一个内存对象"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 也可以结合 tf.Variable() 一块使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('v_scope') as scope1:\n",
    "    Weights1 = tf.get_variable('Weights1', shape=[2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v_scope/Weights1:0\n",
      "v_scope/Weights1:0\n",
      "v_scope_4/bias:0\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('v_scope', reuse=True) as scope2:\n",
    "    Weights2 = tf.get_variable('Weights1')\n",
    "    bias2 = tf.Variable([0.52], name='bias')\n",
    "\n",
    "print Weights1.name\n",
    "print Weights2.name\n",
    "print bias2.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.placeholder() 占位符。* trainable==False *\n",
    "### tf.Variable() 一般变量用这种方式定义。 * 可以选择 trainable 类型 *\n",
    "### tf.get_variable() 一般都是和 tf.variable_scope() 配合使用，从而实现变量共享的功能。 * 可以选择 trainable 类型 *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ph:0\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Tensor(\"ph:0\", shape=(2, 3, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "v1 = tf.placeholder(tf.float32, shape=[2,3,4], name='ph')\n",
    "print v1.name\n",
    "print type(v1)\n",
    "print v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V:0\n",
      "<class 'tensorflow.python.ops.variables.Variable'>\n",
      "<tf.Variable 'V:0' shape=(2,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "v2 = tf.Variable([1,2], dtype=tf.float32, name='V')\n",
    "print v2.name\n",
    "print type(v2)\n",
    "print v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gv1:0\n",
      "<class 'tensorflow.python.ops.variables.Variable'>\n",
      "<tf.Variable 'gv1:0' shape=() dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "v3 = tf.get_variable(name='gv1', shape=[])  \n",
    "print v3.name\n",
    "print type(v3)\n",
    "print v3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 和普通的 python 函数不一样，在一般的函数中，我们对输入进行处理，然后返回一个结果，而函数里边定义的一些局部变量我们就不管了。但是在 TensorFlow 中，我们在函数里边创建了一个变量，就是往 Graph 中添加了一个节点。出了这个函数后，这个节点还是存在于 Graph 中的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eg.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 11 train_able_variables in the Graph: \n",
      "<tf.Variable 'V:0' shape=(2,) dtype=float32_ref>\n",
      "<tf.Variable 'gv:0' shape=() dtype=float32_ref>\n",
      "<tf.Variable 'gv1:0' shape=() dtype=float32_ref>\n",
      "<tf.Variable 'conv1_weights:0' shape=(5, 5, 32, 32) dtype=float32_ref>\n",
      "<tf.Variable 'conv1_biases:0' shape=(32,) dtype=float32_ref>\n",
      "<tf.Variable 'conv2_weights:0' shape=(5, 5, 32, 32) dtype=float32_ref>\n",
      "<tf.Variable 'conv2_biases:0' shape=(32,) dtype=float32_ref>\n",
      "<tf.Variable 'conv1_weights_1:0' shape=(5, 5, 32, 32) dtype=float32_ref>\n",
      "<tf.Variable 'conv1_biases_1:0' shape=(32,) dtype=float32_ref>\n",
      "<tf.Variable 'conv2_weights_1:0' shape=(5, 5, 32, 32) dtype=float32_ref>\n",
      "<tf.Variable 'conv2_biases_1:0' shape=(32,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "def my_image_filter():\n",
    "    conv1_weights = tf.Variable(tf.random_normal([5, 5, 32, 32]),\n",
    "        name=\"conv1_weights\")\n",
    "    conv1_biases = tf.Variable(tf.zeros([32]), name=\"conv1_biases\")\n",
    "    conv2_weights = tf.Variable(tf.random_normal([5, 5, 32, 32]),\n",
    "        name=\"conv2_weights\")\n",
    "    conv2_biases = tf.Variable(tf.zeros([32]), name=\"conv2_biases\")\n",
    "    return None\n",
    "\n",
    "# First call creates one set of 4 variables.\n",
    "result1 = my_image_filter()\n",
    "# Another set of 4 variables is created in the second call.\n",
    "result2 = my_image_filter()\n",
    "# 获取所有的可训练变量\n",
    "vs = tf.trainable_variables()\n",
    "print 'There are %d train_able_variables in the Graph: ' % len(vs)\n",
    "for v in vs:\n",
    "    print v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eg. 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 train_able_variables in the Graph: \n",
      "<tf.Variable 'image_filters/conv1/weights:0' shape=(5, 5, 32, 32) dtype=float32_ref>\n",
      "<tf.Variable 'image_filters/conv1/biases:0' shape=(32,) dtype=float32_ref>\n",
      "<tf.Variable 'image_filters/conv2/weights:0' shape=(5, 5, 32, 32) dtype=float32_ref>\n",
      "<tf.Variable 'image_filters/conv2/biases:0' shape=(32,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "# 下面是定义一个卷积层的通用方式\n",
    "def conv_relu(kernel_shape, bias_shape):\n",
    "    # Create variable named \"weights\".\n",
    "    weights = tf.get_variable(\"weights\", kernel_shape, initializer=tf.random_normal_initializer())\n",
    "    # Create variable named \"biases\".\n",
    "    biases = tf.get_variable(\"biases\", bias_shape, initializer=tf.constant_initializer(0.0))\n",
    "    return None\n",
    "\n",
    "def my_image_filter():\n",
    "    # 按照下面的方式定义卷积层，非常直观，而且富有层次感\n",
    "    with tf.variable_scope(\"conv1\"):\n",
    "        # Variables created here will be named \"conv1/weights\", \"conv1/biases\".\n",
    "        relu1 = conv_relu([5, 5, 32, 32], [32])\n",
    "    with tf.variable_scope(\"conv2\"):\n",
    "        # Variables created here will be named \"conv2/weights\", \"conv2/biases\".\n",
    "        return conv_relu( [5, 5, 32, 32], [32])\n",
    "\n",
    "\n",
    "with tf.variable_scope(\"image_filters\") as scope:\n",
    "    # 下面我们两次调用 my_image_filter 函数，但是由于引入了 变量共享机制\n",
    "    # 可以看到我们只是创建了一遍网络结构。\n",
    "    result1 = my_image_filter()\n",
    "    scope.reuse_variables()\n",
    "    result2 = my_image_filter()\n",
    "\n",
    "\n",
    "# 看看下面，完美地实现了变量共享！！！\n",
    "vs = tf.trainable_variables()\n",
    "print 'There are %d train_able_variables in the Graph: ' % len(vs)\n",
    "for v in vs:\n",
    "    print v"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
